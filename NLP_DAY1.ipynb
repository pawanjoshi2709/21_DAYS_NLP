{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##NLP(Natural Language Processing)\n",
        "\n",
        "The primary goal of NLP is to enable computers to understand, interpret, and generate human-like language in a way that is both meaningful and contextually relevant"
      ],
      "metadata": {
        "id": "OrOam6Z_vfy6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VoU8XeA2TbEk"
      },
      "outputs": [],
      "source": [
        "#importing the libraries for string tokenization\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9niOoD_YU3sh",
        "outputId": "5b08f806-9b16-4612-b8d3-1d49bda4e61f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I started the 21 days challenge. This is the first day of learning NLP.\""
      ],
      "metadata": {
        "id": "B73zbxZAUV2b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize into words\n",
        "words= word_tokenize(text)\n",
        "print(\"tokenized word:\",words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJsPyHbSUo_A",
        "outputId": "e460f2a7-fc8c-48b7-ce3a-5fa8a47febb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenized word: ['I', 'started', 'the', '21', 'days', 'challenge', '.', 'This', 'is', 'the', 'first', 'day', 'of', 'learning', 'NLP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize into sentances\n",
        "sentances = sent_tokenize(text)\n",
        "print(\"tokenized sentance\",sentances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DUzPkk3VQVR",
        "outputId": "f34193a6-c778-4533-a427-1d90553659fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenized sentance ['I started the 21 days challenge.', 'This is the first day of learning NLP.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Natural Language Toolkit (NLTK) library, which is a powerful library for working with human language data, including various tools for NLP.\n",
        " Tokenization is the process of breaking down text into smaller units, such as words or sentences.\n",
        " 'Punkt' is a pre-trained model used by NLTK for tokenization, specifically for splitting text into words and sentences. It contains information about abbreviations and sentence boundaries."
      ],
      "metadata": {
        "id": "QCgdW9Pexuu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing Libraries for frequency distribution\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "iugjYMd3Vjbf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural language processing (NLP) refers to the branch of computer science—and more specifically, the branch of artificial intelligence or AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can. NLP combines computational linguistics—rule-based modeling of human language—with statistical, machine learning, and deep learning models. Together, these technologies enable computers to process human language in the form of text or voice data and to ‘understand’ its full meaning, complete with the speaker or writer’s intent and sentiment.NLP drives computer programs that translate text from one language to another, respond to spoken commands, and summarize large volumes of text rapidly—even in real time. \""
      ],
      "metadata": {
        "id": "-O-7sTsSYMBE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lTa6kuKWjvg",
        "outputId": "87fa0046-49a2-4573-9a16-40962ba1dd74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'language', 'processing', '(NLP)', 'refers', 'to', 'the', 'branch', 'of', 'computer', 'science—and', 'more', 'specifically,', 'the', 'branch', 'of', 'artificial', 'intelligence', 'or', 'AI—concerned', 'with', 'giving', 'computers', 'the', 'ability', 'to', 'understand', 'text', 'and', 'spoken', 'words', 'in', 'much', 'the', 'same', 'way', 'human', 'beings', 'can.', 'NLP', 'combines', 'computational', 'linguistics—rule-based', 'modeling', 'of', 'human', 'language—with', 'statistical,', 'machine', 'learning,', 'and', 'deep', 'learning', 'models.', 'Together,', 'these', 'technologies', 'enable', 'computers', 'to', 'process', 'human', 'language', 'in', 'the', 'form', 'of', 'text', 'or', 'voice', 'data', 'and', 'to', '‘understand’', 'its', 'full', 'meaning,', 'complete', 'with', 'the', 'speaker', 'or', 'writer’s', 'intent', 'and', 'sentiment.NLP', 'drives', 'computer', 'programs', 'that', 'translate', 'text', 'from', 'one', 'language', 'to', 'another,', 'respond', 'to', 'spoken', 'commands,', 'and', 'summarize', 'large', 'volumes', 'of', 'text', 'rapidly—even', 'in', 'real', 'time.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating the word frequency\n",
        "word_frquency = Counter(words)\n",
        "print('word_frquency:',word_frquency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC1ZV3rlWGKd",
        "outputId": "0487d39d-7931-44e7-ec40-ebce6aec0787"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_frquency: Counter({'to': 6, 'the': 6, 'of': 5, 'and': 5, 'text': 4, 'language': 3, 'or': 3, 'in': 3, 'human': 3, 'branch': 2, 'computer': 2, 'with': 2, 'computers': 2, 'spoken': 2, 'Natural': 1, 'processing': 1, '(NLP)': 1, 'refers': 1, 'science—and': 1, 'more': 1, 'specifically,': 1, 'artificial': 1, 'intelligence': 1, 'AI—concerned': 1, 'giving': 1, 'ability': 1, 'understand': 1, 'words': 1, 'much': 1, 'same': 1, 'way': 1, 'beings': 1, 'can.': 1, 'NLP': 1, 'combines': 1, 'computational': 1, 'linguistics—rule-based': 1, 'modeling': 1, 'language—with': 1, 'statistical,': 1, 'machine': 1, 'learning,': 1, 'deep': 1, 'learning': 1, 'models.': 1, 'Together,': 1, 'these': 1, 'technologies': 1, 'enable': 1, 'process': 1, 'form': 1, 'voice': 1, 'data': 1, '‘understand’': 1, 'its': 1, 'full': 1, 'meaning,': 1, 'complete': 1, 'speaker': 1, 'writer’s': 1, 'intent': 1, 'sentiment.NLP': 1, 'drives': 1, 'programs': 1, 'that': 1, 'translate': 1, 'from': 1, 'one': 1, 'another,': 1, 'respond': 1, 'commands,': 1, 'summarize': 1, 'large': 1, 'volumes': 1, 'rapidly—even': 1, 'real': 1, 'time.': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying  the frequency distribution\n",
        "for word , frequency in word_frquency.items():\n",
        "  print(f\"{word}\\t\\t{frequency}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3be6KzGLWwSZ",
        "outputId": "899feccb-5b7c-474f-cfe6-60cdabcd0c49"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural\t\t1\n",
            "language\t\t3\n",
            "processing\t\t1\n",
            "(NLP)\t\t1\n",
            "refers\t\t1\n",
            "to\t\t6\n",
            "the\t\t6\n",
            "branch\t\t2\n",
            "of\t\t5\n",
            "computer\t\t2\n",
            "science—and\t\t1\n",
            "more\t\t1\n",
            "specifically,\t\t1\n",
            "artificial\t\t1\n",
            "intelligence\t\t1\n",
            "or\t\t3\n",
            "AI—concerned\t\t1\n",
            "with\t\t2\n",
            "giving\t\t1\n",
            "computers\t\t2\n",
            "ability\t\t1\n",
            "understand\t\t1\n",
            "text\t\t4\n",
            "and\t\t5\n",
            "spoken\t\t2\n",
            "words\t\t1\n",
            "in\t\t3\n",
            "much\t\t1\n",
            "same\t\t1\n",
            "way\t\t1\n",
            "human\t\t3\n",
            "beings\t\t1\n",
            "can.\t\t1\n",
            "NLP\t\t1\n",
            "combines\t\t1\n",
            "computational\t\t1\n",
            "linguistics—rule-based\t\t1\n",
            "modeling\t\t1\n",
            "language—with\t\t1\n",
            "statistical,\t\t1\n",
            "machine\t\t1\n",
            "learning,\t\t1\n",
            "deep\t\t1\n",
            "learning\t\t1\n",
            "models.\t\t1\n",
            "Together,\t\t1\n",
            "these\t\t1\n",
            "technologies\t\t1\n",
            "enable\t\t1\n",
            "process\t\t1\n",
            "form\t\t1\n",
            "voice\t\t1\n",
            "data\t\t1\n",
            "‘understand’\t\t1\n",
            "its\t\t1\n",
            "full\t\t1\n",
            "meaning,\t\t1\n",
            "complete\t\t1\n",
            "speaker\t\t1\n",
            "writer’s\t\t1\n",
            "intent\t\t1\n",
            "sentiment.NLP\t\t1\n",
            "drives\t\t1\n",
            "programs\t\t1\n",
            "that\t\t1\n",
            "translate\t\t1\n",
            "from\t\t1\n",
            "one\t\t1\n",
            "another,\t\t1\n",
            "respond\t\t1\n",
            "commands,\t\t1\n",
            "summarize\t\t1\n",
            "large\t\t1\n",
            "volumes\t\t1\n",
            "rapidly—even\t\t1\n",
            "real\t\t1\n",
            "time.\t\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#counting the total words\n",
        "word_count = len(words)\n",
        "print(\"Total word count:\", word_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEoo10mbeM9m",
        "outputId": "8245b3ed-9a85-4ff0-c7c6-f8bebb67a55d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total word count: 111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#counting the unique words\n",
        "unique_word = set(words)\n",
        "unique_word_count = len(unique_word)\n",
        "print(\"Total unique word count:\", unique_word_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFh-UpHned3L",
        "outputId": "89b00185-0d0e-44ea-cc43-b5261e215c02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique word count: 77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counitng the sentance\n",
        "sentances = sent_tokenize(text)\n",
        "count_sent = len(sentances)\n",
        "print(\"total sentance count\",count_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkElNYFFgss7",
        "outputId": "4e2b756b-b394-4148-b2fe-485f0a7fa0ee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sentance count 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# longest sentance\n",
        "longest_sentance = max(sentances, key = len)\n",
        "print(\"Longest sentance :\",longest_sentance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6mkKE0Fgsch",
        "outputId": "b7b48d0f-35ad-4c9b-b922-e0707d42d117"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest sentance : Together, these technologies enable computers to process human language in the form of text or voice data and to ‘understand’ its full meaning, complete with the speaker or writer’s intent and sentiment.NLP drives computer programs that translate text from one language to another, respond to spoken commands, and summarize large volumes of text rapidly—even in real time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#removing punctuation from sentances\n",
        "import string\n",
        "\n",
        "def remove_punctuation(Sentance):\n",
        "  translator = str.maketrans(\"\",\"\",string.punctuation)\n",
        "  return Sentance.translate(translator)\n",
        "\n",
        "cleaned_sentance = [remove_punctuation(sentance) for sentance in sentances]\n",
        "print(\"sentance without punctuation:\",cleaned_sentance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9w8BSCYiP8c",
        "outputId": "a0ba1cc1-35b6-4b07-b3ad-4aad26b42466"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentance without punctuation: ['Natural language processing NLP refers to the branch of computer science—and more specifically the branch of artificial intelligence or AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can', 'NLP combines computational linguistics—rulebased modeling of human language—with statistical machine learning and deep learning models', 'Together these technologies enable computers to process human language in the form of text or voice data and to ‘understand’ its full meaning complete with the speaker or writer’s intent and sentimentNLP drives computer programs that translate text from one language to another respond to spoken commands and summarize large volumes of text rapidly—even in real time']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cheacking all punctuation character in string libraries\n",
        "all_punctuation = string.punctuation\n",
        "\n",
        "num_different_punctuation = len(all_punctuation)\n",
        "\n",
        "print(\"Number of different punctuation characters:\", num_different_punctuation, \"all punctuation\" , all_punctuation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAAEYxvIoqt6",
        "outputId": "445d4d69-a258-49b5-dae1-1268b11b0676"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different punctuation characters: 32 all punctuation !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Annotator Creation\n",
        "\n",
        "data = [\n",
        "    (\"i love it\", \"positive\"),\n",
        "    (\"i hate it\", \"negative\"),\n",
        "    (\"this is not what i expected\", \"negative\"),\n",
        "    (\"the quality of this item is poor\", \"positive\")\n",
        "]"
      ],
      "metadata": {
        "id": "73Bzsv14ZRep"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the annotator\n",
        "\n",
        "def annotate_data(data):\n",
        "  annotate_data = []\n",
        "  for text, label in data:\n",
        "    annotate_data.append((text,label))\n",
        "  return annotate_data\n"
      ],
      "metadata": {
        "id": "Okxw6fH1YGTF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#annotate the data\n",
        "annotated_data = annotate_data(data)\n",
        "for text, label in annotated_data:\n",
        "  print(f'Text: {text} \\tLabel: {label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_OR8ofmdCg4",
        "outputId": "1a141617-4741-4871-81ae-772d5da1e6df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: i love it \tLabel: positive\n",
            "Text: i hate it \tLabel: negative\n",
            "Text: this is not what i expected \tLabel: negative\n",
            "Text: the quality of this item is poor \tLabel: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data annotation is responsible for labeling or tagging data with relevant information, typically in order to prepare high-quality training data for  AI models."
      ],
      "metadata": {
        "id": "z35hie6-zDFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization in Text Processing\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCasYWysdoXJ",
        "outputId": "fe52e638-d863-4e1b-ca5a-66ee9060b0aa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "vhugVgoarN0a"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_word = [lemmatizer.lemmatize(word) for word in words]\n",
        "print(\"lemmatized words:\", lemmatized_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vw26x9zroHw",
        "outputId": "f437a5ae-71c7-43dd-e74a-a560ed4a65d9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemmatized words: ['Natural', 'language', 'processing', '(NLP)', 'refers', 'to', 'the', 'branch', 'of', 'computer', 'science—and', 'more', 'specifically,', 'the', 'branch', 'of', 'artificial', 'intelligence', 'or', 'AI—concerned', 'with', 'giving', 'computer', 'the', 'ability', 'to', 'understand', 'text', 'and', 'spoken', 'word', 'in', 'much', 'the', 'same', 'way', 'human', 'being', 'can.', 'NLP', 'combine', 'computational', 'linguistics—rule-based', 'modeling', 'of', 'human', 'language—with', 'statistical,', 'machine', 'learning,', 'and', 'deep', 'learning', 'models.', 'Together,', 'these', 'technology', 'enable', 'computer', 'to', 'process', 'human', 'language', 'in', 'the', 'form', 'of', 'text', 'or', 'voice', 'data', 'and', 'to', '‘understand’', 'it', 'full', 'meaning,', 'complete', 'with', 'the', 'speaker', 'or', 'writer’s', 'intent', 'and', 'sentiment.NLP', 'drive', 'computer', 'program', 'that', 'translate', 'text', 'from', 'one', 'language', 'to', 'another,', 'respond', 'to', 'spoken', 'commands,', 'and', 'summarize', 'large', 'volume', 'of', 'text', 'rapidly—even', 'in', 'real', 'time.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization is a crucial step in text processing. It reduce word to their base form.\n",
        "The WordNet Lemmatizer is a tool provided by the Natural Language Toolkit (NLTK) for lemmatizing words based on the WordNet lexical database.\n",
        "WordNet is a lexical database of the English language that includes information about words, their meanings, and relationships.\n"
      ],
      "metadata": {
        "id": "AS8RnamhuVK7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HksLtZGbsuex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}