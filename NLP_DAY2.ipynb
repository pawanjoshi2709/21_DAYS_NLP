{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nJ5RJUI3B-1s"
      },
      "outputs": [],
      "source": [
        "#word embedding Word2vec\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJxaK5ZrXNQl",
        "outputId": "b1ac7559-feca-4e2b-b5f1-30b22fb956f1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Word embedding is a powerful technique in natural language processing, capturing semantic relationships between words. Utilizing algorithms like Word2Vec or GloVe, it transforms words into high-dimensional vectors. These vectors preserve contextual information, facilitating tasks like sentiment analysis, machine translation, and document clustering\""
      ],
      "metadata": {
        "id": "VtrJVrr0Iw9o"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(text)\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n"
      ],
      "metadata": {
        "id": "e1sFtky_JIMU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train word2vec model\n",
        "model = Word2Vec(tokenized_sentences, vector_size=100, window=5, min_count=1, sg=0)\n"
      ],
      "metadata": {
        "id": "aT8zkAnLX90J"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#acess word vectors\n",
        "word_vectors = model.wv\n",
        "vector = word_vectors['word']\n",
        "print(\"vector for word\",vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVHQNIx0YltG",
        "outputId": "47610b39-6d75-4669-e106-a27a3b04521f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector for word [-4.7877301e-03 -4.3088831e-03 -4.8047639e-03 -9.8078838e-03\n",
            " -7.7606901e-04 -7.8003672e-03 -4.8259199e-03 -7.3728049e-03\n",
            "  9.9300118e-03 -1.3649601e-03 -7.7508264e-03  5.5093332e-03\n",
            " -8.0684284e-03 -1.9051839e-03  2.7484007e-03 -7.0880977e-03\n",
            " -8.7190233e-03 -6.6439309e-03  7.4664587e-03  9.0433713e-03\n",
            "  4.0041995e-03  2.4071313e-03  4.1500423e-03 -4.0752497e-03\n",
            "  9.7585255e-03  6.8997387e-03  4.0977001e-03  8.9474991e-03\n",
            " -8.3900252e-03  9.3544787e-04  8.9066550e-03 -9.4757846e-04\n",
            " -6.7378129e-03 -2.2899285e-03 -2.7877369e-03 -2.5010272e-03\n",
            " -1.8444222e-03  7.2917496e-03 -3.1157737e-04  4.2268690e-03\n",
            " -3.7631996e-03  8.2187662e-03 -6.4854939e-03 -9.3289278e-03\n",
            " -4.1385097e-03 -7.3735467e-03 -4.8864479e-03  4.8679614e-04\n",
            "  2.3911817e-03  1.7403081e-03  5.0138067e-03 -1.4038198e-03\n",
            "  2.2743368e-03  3.5204491e-04  7.8353090e-03  8.0244029e-03\n",
            " -1.9645488e-03  1.2591110e-03 -6.0412632e-03 -4.7685327e-03\n",
            " -6.9669224e-03  1.4424011e-06 -4.8934356e-03 -4.0285895e-03\n",
            "  1.4983392e-03  2.6330776e-03 -9.1111213e-03  1.7584095e-03\n",
            "  5.1168837e-03  4.1664238e-03 -2.9049576e-03  9.4922837e-03\n",
            "  9.4508082e-03 -1.9382636e-05  8.7408029e-04 -9.2420038e-03\n",
            " -4.8061609e-03 -8.4339583e-05  4.0366133e-03  1.6090098e-04\n",
            " -8.7393783e-03  5.8038249e-03 -7.4251960e-03  8.5603949e-03\n",
            "  5.5220011e-03 -6.7737419e-03  2.8462680e-03  7.7239661e-03\n",
            " -6.1059389e-03 -6.5397853e-03  9.2156641e-03  1.8138752e-03\n",
            "  9.7183296e-03 -9.9069485e-03 -1.4922764e-03  6.9023152e-03\n",
            " -1.4603232e-03 -1.7545023e-03 -7.1009761e-03 -5.6610974e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finding similar words\n",
        "similar_words = model.wv.most_similar('embedding',topn= 3)\n",
        "print(\"similar words to'embedding' :\", similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQusg44XZBDS",
        "outputId": "1ce3875b-7c32-461f-f7fd-04f7f895e9ed"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similar words to'embedding' : [('between', 0.31900984048843384), ('sentiment', 0.18884754180908203), ('in', 0.16206954419612885)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec is a popular word embedding technique in natural language processing. Developed by Google, it represents words as dense vectors in a continuous vector space. It employs two models: Continuous Bag of Words (CBOW) predicts a word from its context, while Skip-gram predicts context words given a target word. These embeddings capture semantic relationships, facilitating tasks like sentiment analysis and machine translation, and are learned from large text corpora, enabling efficient representation of words with similar meanings in a numerical format.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GHnfop3_3qtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#co-occurrence vectors\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "2adOMlVRMCbV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 2\n",
        "co_occurrence_matrix = defaultdict(lambda: defaultdict(int))\n",
        "for sentence in tokenized_sentences:\n",
        "  for i , target_word in enumerate(sentence):\n",
        "    for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "      if i != j:\n",
        "        context_word = sentence[j]\n",
        "        co_occurrence_matrix[target_word][context_word] +=1\n",
        "\n"
      ],
      "metadata": {
        "id": "T_k2cpFTZz6u"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for target_word, context_word in co_occurrence_matrix.items():\n",
        "  print(target_word, context_word)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChCnoM1MPKr7",
        "outputId": "3dfd924a-50b8-4eea-ec71-070ef28cc2c5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word defaultdict(<class 'int'>, {'embedding': 1, 'is': 1})\n",
            "embedding defaultdict(<class 'int'>, {'word': 1, 'is': 1, 'a': 1})\n",
            "is defaultdict(<class 'int'>, {'word': 1, 'embedding': 1, 'a': 1, 'powerful': 1})\n",
            "a defaultdict(<class 'int'>, {'embedding': 1, 'is': 1, 'powerful': 1, 'technique': 1})\n",
            "powerful defaultdict(<class 'int'>, {'is': 1, 'a': 1, 'technique': 1, 'in': 1})\n",
            "technique defaultdict(<class 'int'>, {'a': 1, 'powerful': 1, 'in': 1, 'natural': 1})\n",
            "in defaultdict(<class 'int'>, {'powerful': 1, 'technique': 1, 'natural': 1, 'language': 1})\n",
            "natural defaultdict(<class 'int'>, {'technique': 1, 'in': 1, 'language': 1, 'processing': 1})\n",
            "language defaultdict(<class 'int'>, {'in': 1, 'natural': 1, 'processing': 1, ',': 1})\n",
            "processing defaultdict(<class 'int'>, {'natural': 1, 'language': 1, ',': 1, 'capturing': 1})\n",
            ", defaultdict(<class 'int'>, {'language': 1, 'processing': 1, 'capturing': 1, 'semantic': 1, 'or': 1, 'glove': 1, 'it': 1, 'transforms': 1, 'contextual': 1, 'information': 1, 'facilitating': 1, 'tasks': 1, 'sentiment': 1, 'analysis': 1, 'machine': 2, 'translation': 2, 'and': 1, 'document': 1})\n",
            "capturing defaultdict(<class 'int'>, {'processing': 1, ',': 1, 'semantic': 1, 'relationships': 1})\n",
            "semantic defaultdict(<class 'int'>, {',': 1, 'capturing': 1, 'relationships': 1, 'between': 1})\n",
            "relationships defaultdict(<class 'int'>, {'capturing': 1, 'semantic': 1, 'between': 1, 'words': 1})\n",
            "between defaultdict(<class 'int'>, {'semantic': 1, 'relationships': 1, 'words': 1, '.': 1})\n",
            "words defaultdict(<class 'int'>, {'relationships': 1, 'between': 1, '.': 1, 'it': 1, 'transforms': 1, 'into': 1, 'high-dimensional': 1})\n",
            ". defaultdict(<class 'int'>, {'between': 1, 'words': 1, 'high-dimensional': 1, 'vectors': 1})\n",
            "utilizing defaultdict(<class 'int'>, {'algorithms': 1, 'like': 1})\n",
            "algorithms defaultdict(<class 'int'>, {'utilizing': 1, 'like': 1, 'word2vec': 1})\n",
            "like defaultdict(<class 'int'>, {'utilizing': 1, 'algorithms': 1, 'word2vec': 1, 'or': 1, 'facilitating': 1, 'tasks': 1, 'sentiment': 1, 'analysis': 1})\n",
            "word2vec defaultdict(<class 'int'>, {'algorithms': 1, 'like': 1, 'or': 1, 'glove': 1})\n",
            "or defaultdict(<class 'int'>, {'like': 1, 'word2vec': 1, 'glove': 1, ',': 1})\n",
            "glove defaultdict(<class 'int'>, {'word2vec': 1, 'or': 1, ',': 1, 'it': 1})\n",
            "it defaultdict(<class 'int'>, {'glove': 1, ',': 1, 'transforms': 1, 'words': 1})\n",
            "transforms defaultdict(<class 'int'>, {',': 1, 'it': 1, 'words': 1, 'into': 1})\n",
            "into defaultdict(<class 'int'>, {'transforms': 1, 'words': 1, 'high-dimensional': 1, 'vectors': 1})\n",
            "high-dimensional defaultdict(<class 'int'>, {'words': 1, 'into': 1, 'vectors': 1, '.': 1})\n",
            "vectors defaultdict(<class 'int'>, {'into': 1, 'high-dimensional': 1, '.': 1, 'these': 1, 'preserve': 1, 'contextual': 1})\n",
            "these defaultdict(<class 'int'>, {'vectors': 1, 'preserve': 1})\n",
            "preserve defaultdict(<class 'int'>, {'these': 1, 'vectors': 1, 'contextual': 1, 'information': 1})\n",
            "contextual defaultdict(<class 'int'>, {'vectors': 1, 'preserve': 1, 'information': 1, ',': 1})\n",
            "information defaultdict(<class 'int'>, {'preserve': 1, 'contextual': 1, ',': 1, 'facilitating': 1})\n",
            "facilitating defaultdict(<class 'int'>, {'information': 1, ',': 1, 'tasks': 1, 'like': 1})\n",
            "tasks defaultdict(<class 'int'>, {',': 1, 'facilitating': 1, 'like': 1, 'sentiment': 1})\n",
            "sentiment defaultdict(<class 'int'>, {'tasks': 1, 'like': 1, 'analysis': 1, ',': 1})\n",
            "analysis defaultdict(<class 'int'>, {'like': 1, 'sentiment': 1, ',': 1, 'machine': 1})\n",
            "machine defaultdict(<class 'int'>, {'analysis': 1, ',': 2, 'translation': 1})\n",
            "translation defaultdict(<class 'int'>, {',': 2, 'machine': 1, 'and': 1})\n",
            "and defaultdict(<class 'int'>, {'translation': 1, ',': 1, 'document': 1, 'clustering': 1})\n",
            "document defaultdict(<class 'int'>, {',': 1, 'and': 1, 'clustering': 1})\n",
            "clustering defaultdict(<class 'int'>, {'and': 1, 'document': 1})\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Co-occurrence matrices are a fundamental concept in NLP, and we can use them to represent the relationship between elements in a text corpus. Usually, in NLP, we work with a collection of text or text corpus. Elements of text corpus can refer to sentences, words, phrases, or any other linguistic unit of interest.\n",
        "\n",
        "With co-occurrence matrices, it is possible to represent these elements using rows and columns of a matrix. More precisely, each row and column of a matrix represents a unique element of a text corpus. Cells of the matrix represent the number of times two elements appear together in a predefined context. The context can be a document, sentence, word window, or any other relevant unit"
      ],
      "metadata": {
        "id": "FIyZag2M4Lhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#doc2vec"
      ],
      "metadata": {
        "id": "2gmuqTLlPdxw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n"
      ],
      "metadata": {
        "id": "rNh959ZMBlDh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_data = [TaggedDocument(words=words, tags = [str(idx)]) for idx ,words in enumerate(tokenized_sentences)]"
      ],
      "metadata": {
        "id": "eX6591U8BzIs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the doc2vec model\n",
        "model = Doc2Vec(vector_size=100, window=5, min_count = 1, dm=1, epochs = 20)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples = model.corpus_count, epochs = model.epochs)"
      ],
      "metadata": {
        "id": "ebvk2gGYC3BS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vector = model.infer_vector(word_tokenize(\"DOC2Vec is a powerful tool for documents embeddings\"))\n",
        "print(doc_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MKadgSpDbTP",
        "outputId": "b803f173-b4fe-4e02-ea16-7d3fc5dc97ac"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.8006394e-03 -7.6809665e-04 -1.6907499e-03 -2.1911014e-03\n",
            "  1.6654968e-03  3.8139229e-03  3.3960289e-03 -4.2499080e-03\n",
            "  3.9905277e-03 -2.0782156e-03 -4.0397733e-03  3.5720621e-03\n",
            "  7.4088655e-04  3.4847155e-03 -3.3172825e-03  2.8531004e-03\n",
            " -1.6846898e-04  4.7689835e-03  2.8872620e-03 -2.0982616e-03\n",
            "  3.5755602e-03  3.1527507e-03  3.5843158e-03  8.0920977e-04\n",
            " -3.2826650e-03 -3.4659245e-04  1.8716755e-03 -2.2667188e-03\n",
            " -2.8462415e-03  8.7195536e-04  1.2657329e-03  4.1245185e-03\n",
            "  5.6471606e-04 -2.5968167e-03 -1.6592431e-03  1.3917380e-03\n",
            " -4.9890880e-03  4.6170740e-03 -2.7549677e-03 -1.3207658e-03\n",
            "  8.7225251e-04 -3.7129656e-03  1.4312005e-03  3.9877831e-03\n",
            "  3.8101235e-03 -1.4723151e-03 -2.4656674e-03  3.1810470e-03\n",
            "  1.0947608e-03 -2.3028874e-03 -1.0190174e-03  1.4492406e-05\n",
            " -2.5434566e-03  3.1412757e-04  4.6439879e-03 -8.9946348e-04\n",
            " -4.1318811e-03 -1.7177417e-03 -1.4343650e-04  9.7687756e-05\n",
            "  1.3573680e-03  4.9959756e-03 -1.7995589e-03 -4.3527400e-03\n",
            "  4.5892517e-03 -4.4149770e-03  3.1833618e-03  2.0151187e-03\n",
            "  2.3481525e-03 -4.2476770e-03  4.6416989e-04  2.2369386e-03\n",
            "  2.6511992e-03 -4.1337046e-04 -2.9958831e-04 -4.1390220e-03\n",
            " -4.5664529e-03 -2.7946925e-03  2.1343643e-03 -5.5471412e-04\n",
            "  4.4053927e-04  4.9480251e-03  2.6124159e-03 -3.0305432e-03\n",
            " -5.7524495e-04 -4.1565898e-05 -4.3678959e-03 -1.1027397e-03\n",
            " -9.9213549e-04  7.3282157e-05  2.2699654e-03 -3.7766848e-04\n",
            " -1.6962847e-03 -3.8708281e-03 -4.1836826e-03 -3.2052927e-04\n",
            "  2.3601186e-03 -1.0486573e-03 -2.8692558e-03 -4.0643243e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc2vec is a technique that extracts semantic information from documents and then uses that information to classify the documents. By applying Doc2vec to existing documents, it becomes possible for AI software to rapidly identify similar topics in a large collection of text without having to read the entire corpus"
      ],
      "metadata": {
        "id": "gBQncb7Q2oCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#textblob\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "quTJv_fWon5x"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('brown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLdW1iMGpLRO",
        "outputId": "534803eb-864c-42c5-b854-6577ef0a0a72"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Sunil Chhetri (born 3 August 1984) is an Indian professional footballer who plays as a forward and captains both Indian Super League club Bengaluru FC and the India national team. He is known for his link-up play, goal scoring abilities, and leadership.[3][4] He is the third-highest international goalscorer among active players, behind only Cristiano Ronaldo and Lionel Messi,[5][6] fourth overall, and is also the most-capped player and the all-time top goalscorer of the India national team. He is widely regarded as one of the greatest Indian footballers of all time for his contributions for the country'"
      ],
      "metadata": {
        "id": "w6Yb7V1PpR01"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# introduction to text blob\n",
        "intro_blob = TextBlob(text)\n",
        "print(\"introduction to text blob: \", intro_blob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV2Qs8INprzM",
        "outputId": "d76fe932-d082-4563-e977-3135a1781c85"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "introduction to text blob:  Sunil Chhetri (born 3 August 1984) is an Indian professional footballer who plays as a forward and captains both Indian Super League club Bengaluru FC and the India national team. He is known for his link-up play, goal scoring abilities, and leadership.[3][4] He is the third-highest international goalscorer among active players, behind only Cristiano Ronaldo and Lionel Messi,[5][6] fourth overall, and is also the most-capped player and the all-time top goalscorer of the India national team. He is widely regarded as one of the greatest Indian footballers of all time for his contributions for the country\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"I'm extremely disappointed with the quality of this item. It broke after just a few uses.\""
      ],
      "metadata": {
        "id": "GKIM4By5tcQD"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_blob = TextBlob(text1)\n",
        "polarity = sentiment_blob.sentiment.polarity\n",
        "sentiment = 'positive' if polarity >0 else 'negative' if polarity < 0 else 'neutral'\n",
        "print('sentiment analysis:',sentiment, \"(Polarity:\" ,polarity,\")\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IphaewLwsUwv",
        "outputId": "a3afe20c-2c96-4fdd-c86f-e147fa343e88"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment analysis: negative (Polarity: -0.475 )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b2TQx-DtubH",
        "outputId": "bcac84bd-809a-483b-9beb-0b0eae834c58"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#part of speech tagging and noun phrase extraction\n",
        "pos_blob = TextBlob(\"the black cat is sleeping on the soft mat\")\n",
        "pos_tags = pos_blob.tags\n",
        "noun_phrases = pos_blob.noun_phrases\n",
        "print(\"part of speech tags:\" ,pos_tags)\n",
        "print('noun pharse', noun_phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAWl5-g2uZhI",
        "outputId": "fc57889f-059b-4e6b-fc70-832a908a8bf9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part of speech tags: [('the', 'DT'), ('black', 'JJ'), ('cat', 'NN'), ('is', 'VBZ'), ('sleeping', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('soft', 'JJ'), ('mat', 'NN')]\n",
            "noun pharse ['black cat', 'soft mat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, 'DT' stands for determiner, 'JJ' for adjective, 'NN' for noun, 'VBZ' for verb (present tense, 3rd person singular), 'VBG' for verb (gerund or present participle), 'IN' for preposition or subordinating conjunction, etc."
      ],
      "metadata": {
        "id": "B3Ra_Gx2v8Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subclass textblob to add custom methods\n",
        "class ExtendedTextBlob(TextBlob):\n",
        "  def my_custom_function(self,name):\n",
        "    return \"we create our sub class\" ,name\n",
        "\n",
        "extended_blob = ExtendedTextBlob(\"this is some text\")\n",
        "result = extended_blob.my_custom_function('class1')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cAX3ukYymcq",
        "outputId": "829d0875-1630-4a6e-dcc2-82a9e9d5642a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('we create our sub class', 'class1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#language taranslation and language detection\n",
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytaLBIuDvNv2",
        "outputId": "e2056364-d13d-4a6a-d049-0b65e7e030a6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.11.17)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.1.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "translator =Translator()\n",
        "original_text = \"अरे दोस्तों आप कैसे हो\"\n",
        "detected_lang = translator.detect(original_text).lang\n",
        "translated_text = translator.translate(original_text, src = detected_lang, dest ='en').text\n",
        "\n",
        "print(\"original text:\",original_text)\n",
        "print(\"Detected language\",detected_lang)\n",
        "print(\"Translated Text\",translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9aX-7gnwRzm",
        "outputId": "2639aeee-dff9-4252-ccd9-03f1467957ca"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text: अरे दोस्तों आप कैसे हो\n",
            "Detected language hi\n",
            "Translated Text Hey guys how are you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TextBlob is a Python library for processing textual data in natural language processing (NLP). It simplifies common NLP tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. TextBlob is built on top of NLTK (Natural Language Toolkit) and provides a simple API for beginners while offering flexibility for advanced users. It is widely used for quick prototyping and analysis of text data due to its ease of use and effectiveness in handling various NLP tasks."
      ],
      "metadata": {
        "id": "x-E0W4lh4msv"
      }
    }
  ]
}